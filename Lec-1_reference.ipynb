{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aefe56f",
   "metadata": {},
   "source": [
    "# Quick Python Refresher\n",
    "\n",
    "Topics:\n",
    "- Variables and Data Types\n",
    "- Control Structures (if, for, while)\n",
    "- Functions\n",
    "- Lists, Tuples, and Dictionaries\n",
    "- Basic class and object concepts (Important for understanding PyTorch modules)\n",
    "- Importing Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d86c1074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! AI here I come\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello! AI here I come\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97fae67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are going to build neural networks\n"
     ]
    }
   ],
   "source": [
    "message = \"We are going to build neural networks\"\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708244ad",
   "metadata": {},
   "source": [
    "## Variables and Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db19535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are training model called: Skin Lesion Classifier with 2 classes at learning rate 0.001\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_classes = 2 # integer\n",
    "learning_rate = 0.001 # float\n",
    "\n",
    "model_name = \"Skin Lesion Classifier\" # string\n",
    "is_trained = False # boolean\n",
    "\n",
    "# way to print variables in a string\n",
    "print(f\"We are training model called: {model_name} with {num_classes} classes at learning rate {learning_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce328b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our class names are: ['benign', 'malignant']\n",
      "First class is: benign\n",
      "Updated class names: ['benign', 'malignant', 'unknown']\n"
     ]
    }
   ],
   "source": [
    "class_names = [\"benign\", \"malignant\"]  # list. Ordered collection of items\n",
    "print(\"Our class names are:\", class_names) # other way to print variables\n",
    "\n",
    "# accessing list items. Its 0 based indexing\n",
    "first_class = class_names[0]\n",
    "print(\"First class is:\", first_class)\n",
    "\n",
    "# adding item to list\n",
    "class_names.append(\"unknown\")\n",
    "print(\"Updated class names:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcbc377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration: {'model_name': 'LeNet', 'learning_rate': 0.001, 'num_classes': 2, 'epochs': 10, 'optimizers': ['SGD', 'Adam']}\n",
      "Learning rate from config: 0.001\n",
      "Updated configuration: {'model_name': 'LeNet', 'learning_rate': 0.001, 'num_classes': 2, 'epochs': 10, 'optimizers': ['SGD', 'Adam'], 'batch_size': 32}\n"
     ]
    }
   ],
   "source": [
    "# dictionary. Key-value pairs\n",
    "config = {\n",
    "    \"model_name\": \"LeNet\", # the model which laid foundation for CNNs\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"num_classes\": num_classes, # can also use variables as values\n",
    "    \"epochs\": 10,\n",
    "    \"optimizers\": [\"SGD\", \"Adam\"] # can also have lists as values\n",
    "}\n",
    "# we can also have nested dictionaries\n",
    "\n",
    "print(\"Configuration:\", config)\n",
    "\n",
    "# acccessing dictionary items. The keys are used to access values\n",
    "lr = config[\"learning_rate\"]\n",
    "print(\"Learning rate from config:\", lr)\n",
    "\n",
    "# adding new key-value pair. We can just direcltly assign value to a new key\n",
    "config[\"batch_size\"] = 32\n",
    "print(\"Updated configuration:\", config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "904ddc62",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'momentum'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# common error with dictionaries is trying to access a key that doesn't exist\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# for example\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmomentum\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)  \u001b[38;5;66;03m# This will raise a KeyError\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: 'momentum'"
     ]
    }
   ],
   "source": [
    "# common error with dictionaries is trying to access a key that doesn't exist\n",
    "# for example\n",
    "print(config[\"momentum\"])  # This will raise a KeyError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dbb33b",
   "metadata": {},
   "source": [
    "## Loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d393a0f",
   "metadata": {},
   "source": [
    "`for` loop: 2 main ways\n",
    "1. using `range()` just like other languages \n",
    "2. iterating over collections like lists and dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb08949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number from range: 0\n",
      "Number from range: 1\n",
      "Number from range: 2\n",
      "Number from range: 3\n",
      "Number from range: 4\n"
     ]
    }
   ],
   "source": [
    "# using range()\n",
    "for number in range(5): # prints numbers from 0 to 4. Always goes up to (n-1). No hassle of defining loop variable, condition and increment\n",
    "    print(\"Number from range:\", number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57e5903b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class name from list: benign\n",
      "Class name from list: malignant\n",
      "Class name from list: unknown\n"
     ]
    }
   ],
   "source": [
    "# using list. We can just iterate over the list and get items directly\n",
    "for name in class_names:\n",
    "    print(\"Class name from list:\", name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27205c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: model_name, Value: LeNet\n",
      "Key: learning_rate, Value: 0.001\n",
      "Key: num_classes, Value: 2\n",
      "Key: epochs, Value: 10\n",
      "Key: optimizers, Value: ['SGD', 'Adam']\n",
      "Key: batch_size, Value: 32\n"
     ]
    }
   ],
   "source": [
    "# we can also iterate over dictionary items. By default, iterating over a dictionary gives us the keys\n",
    "for item in config:\n",
    "    print(f\"Key: {item}, Value: {config[item]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d062758",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b38d881f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LeNet for 10 epochs at learning rate 0.001\n",
      "Model accuracy: 85.0%\n"
     ]
    }
   ],
   "source": [
    "# functions\n",
    "def train_model(model_name, learning_rate, epochs):\n",
    "    print(f\"Training {model_name} for {epochs} epochs at learning rate {learning_rate}\")\n",
    "    \n",
    "# with return value\n",
    "def calculate_accuracy(correct, total):\n",
    "    accuracy = (correct / total) * 100\n",
    "    return accuracy\n",
    "\n",
    "# calling functions\n",
    "train_model(\"LeNet\", 0.001, 10)\n",
    "acc = calculate_accuracy(85, 100)\n",
    "print(f\"Model accuracy: {acc}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99acc264",
   "metadata": {},
   "source": [
    "## Classes and Objects\n",
    "\n",
    "Think of classes as blueprints for creating objects. Objects are instances of classes. Think of object as real-world entities created using the blueprint provided by the class.\n",
    "\n",
    "In layman terms, a class can be think of as blueprint for house. The object is the actual house built using that blueprint.\n",
    "\n",
    "Its good idea to understand classes and objects thoroughly as PyTorch heavily uses OOP concepts. For example, when you create a neural network in PyTorch, you typically define a class that inherits from `torch.nn.Module`. Each layer of the network is an object created from classes like `torch.nn.Linear`, `torch.nn.Conv2d`, etc. \n",
    "\n",
    "Before next week, please go through basic OOP concepts in Python. Any good online tutorial or resource will do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cb6143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a simple class. \n",
    "class NeuralNetwork:\n",
    "    def __init__(self, name, num_classes):\n",
    "        self.name = name # these are known as attributes or properties\n",
    "        self.num_classes = num_classes\n",
    "        self.is_trained = False\n",
    "    \n",
    "    def train(self, epochs):\n",
    "        print(f\"Training {self.name} for {epochs} epochs...\")\n",
    "        self.is_trained = True\n",
    "    \n",
    "    def evaluate(self):\n",
    "        if self.is_trained:\n",
    "            print(f\"{self.name} is evaluated.\")\n",
    "        else:\n",
    "            print(f\"{self.name} is not trained yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b2531e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Skin Lesion Classifier for 10 epochs...\n",
      "Skin Lesion Classifier is evaluated.\n"
     ]
    }
   ],
   "source": [
    "# using the class to create objects\n",
    "nn = NeuralNetwork(\"Skin Lesion Classifier\", 2) # this creates an object of NeuralNetwork class\n",
    "nn.train(10) # accessing methods using the object\n",
    "nn.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9219b81",
   "metadata": {},
   "source": [
    "# Pytorch Basics and Fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0120c17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's import the pytorch library\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79f31b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.8.0\n"
     ]
    }
   ],
   "source": [
    "# we can check version of any installed library using the __version__ attribute\n",
    "print(\"PyTorch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbc0aec",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbe644d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D Tensor (Vector:)\n",
      "tensor([1, 2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "# 1D tensor\n",
    "tensor_1d = torch.tensor([1, 2, 3, 4, 5])\n",
    "print(\"1D Tensor (Vector):\")\n",
    "print(tensor_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dc20a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D Tensor (Matrix):\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# 2D tensor\n",
    "tensor_2d = torch.tensor([\n",
    "    [1,2,3],\n",
    "    [4,5,6],\n",
    "])\n",
    "print(\"2D Tensor (Matrix):\")\n",
    "print(tensor_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d1186f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of 1D tensor: torch.Size([5])\n",
      "Shape of 2D tensor: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# tensors have shapes. Shape is like the dimensions of the tensor\n",
    "print(\"Shape of 1D tensor:\", tensor_1d.shape)\n",
    "print(\"Shape of 2D tensor:\", tensor_2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "54b99b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor before adding 10: tensor([1, 2, 3, 4, 5])\n",
      "Tensor after adding 10: tensor([11, 12, 13, 14, 15])\n",
      "Tensor before multiplying by 2: tensor([1, 2, 3, 4, 5])\n",
      "Tensor after multiplying by 2: tensor([ 2,  4,  6,  8, 10])\n"
     ]
    }
   ],
   "source": [
    "# operations on tensors\n",
    "tensor_sum = tensor_1d + 10 # adding scalar to tensor\n",
    "print(\"Tensor before adding 10:\", tensor_1d)\n",
    "print(\"Tensor after adding 10:\", tensor_sum)\n",
    "\n",
    "# multiplying two tensors\n",
    "tensor_mult = tensor_1d * 2\n",
    "print(\"Tensor before multiplying by 2:\", tensor_1d)\n",
    "print(\"Tensor after multiplying by 2:\", tensor_mult)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd704e13",
   "metadata": {},
   "source": [
    "## Device Management "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c691ed6e",
   "metadata": {},
   "source": [
    "Another important concept in pytorch is device management. Tensors can be stored and processed on different devices, such as CPU or GPU. Using a GPU can significantly speed up computations, especially for large-scale neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bf8cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available. Using CPU.\n",
      "Device of 1D tensor before moving: cpu\n",
      "Device of 1D tensor after moving: cpu\n"
     ]
    }
   ],
   "source": [
    "# we can check if a GPU is available and check the device our tensor is on and move it if needed\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # GPU\n",
    "    print(\"GPU is available. Using GPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")   # CPU\n",
    "    print(\"GPU not available. Using CPU.\")\n",
    "    \n",
    "# checking device of tensor\n",
    "print(\"Device of 1D tensor before moving:\", tensor_1d.device)\n",
    "# moving tensor to the selected device\n",
    "tensor_1d = tensor_1d.to(device)\n",
    "print(\"Device of 1D tensor after moving:\", tensor_1d.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac850f2f",
   "metadata": {},
   "source": [
    "This is the most pain in ahh part about pytorch. You have to manually manage devices. For computation to be performed on tensors, all the tensors involved must be on the same device. If they are not, you will get runtime errors. So always ensure that tensors are on the same device before performing operations on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2dde1023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of 1D tensor: torch.int64\n",
      "Float Tensor: tensor([1., 2., 3.])\n",
      "Data type of Float Tensor: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# checking data type of tensor\n",
    "print(\"Data type of 1D tensor:\", tensor_1d.dtype)\n",
    "\n",
    "# float tensor\n",
    "float_tensor = torch.tensor([1.0, 2.0, 3.0])\n",
    "print(\"Float Tensor:\", float_tensor)\n",
    "print(\"Data type of Float Tensor:\", float_tensor.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54564f89",
   "metadata": {},
   "source": [
    "## Random tensor creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a2651e",
   "metadata": {},
   "source": [
    "We often need to create tensors of specific shape filled with random values or zeros. PyTorch provides convenient functions for this.\n",
    "\n",
    "To make sure the random tensors are reproducible, we can set a random seed using `torch.Generator().manual_seed()`. This ensures that every time we run the code, we get the same random values. The seed value can be any integer; using the same seed will always produce the same random tensor. The choice of seed value 42 is historically popular in programming and computer science as a reference to \"The Hitchhiker's Guide to the Galaxy\" by Douglas Adams, where 42 is humorously presented as the \"answer to the ultimate question of life, the universe, and everything.\".\n",
    "\n",
    "This is especially useful for debugging and testing, as it allows us to have consistent results across different runs of the code.\n",
    "\n",
    "Working of random seed? Its more of theoretical concept. Good resource if you want to deep dive look at this [stackoverflow discussion](https://stackoverflow.com/questions/21494489/what-does-numpy-random-seed0-do). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552e6adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor (3x4):\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "Zero Tensor (2x5):\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "One Tensor (2x3):\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "random_tensor = torch.rand((3, 4), generator=torch.Generator().manual_seed(42))  # 3x4 tensor with random values. It will have values between 0 and 1. For integer random tensors, we can use torch.randint()\n",
    "zero_tensor = torch.zeros((2, 5))   # 2x5 tensor filled with zeros\n",
    "one_tensor = torch.ones((2,3))      # 2x3 tensor filled with ones\n",
    "\n",
    "print(\"Random Tensor (3x4):\")\n",
    "print(random_tensor)\n",
    "\n",
    "print(\"Zero Tensor (2x5):\")\n",
    "print(zero_tensor)\n",
    "\n",
    "print(\"One Tensor (2x3):\")\n",
    "print(one_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b927eb00",
   "metadata": {},
   "source": [
    "## Automatic Differentiation and Computational Graphs \n",
    "\n",
    "The heart of PyTorch's deep learning capabilities lies in its automatic differentiation engine, known as Autograd. Autograd allows PyTorch to automatically compute gradients for tensor operations, which is essential for training neural networks using backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0494aa27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=2.0\n",
      "y=x**2 + 3*x + 5=15.0\n"
     ]
    }
   ],
   "source": [
    "# create a tensor and tell pytorch to track operations on it for automatic differentiation\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "\n",
    "# define a simple function\n",
    "y = x**2 + 3*x + 5\n",
    "\n",
    "print(f\"x={x}\")\n",
    "print(f\"y=x**2 + 3*x + 5={y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f5dbe92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of y with respect to x (dy/dx) at x=2.0 is 7.0\n"
     ]
    }
   ],
   "source": [
    "# now magic : calculate the gradient of y with respect to x\n",
    "y.backward()  # this computes the gradient\n",
    "\n",
    "print(f\"Gradient of y with respect to x (dy/dx) at x={x.item()} is {x.grad.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a32a86a",
   "metadata": {},
   "source": [
    "### Visualizing the computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af99ba0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 14.0.1 (20251006.0113)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"202pt\" height=\"337pt\"\n",
       " viewBox=\"0.00 0.00 202.00 337.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 333.25)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-333.25 198,-333.25 198,4 -4,4\"/>\n",
       "<!-- 5720181328 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>5720181328</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"124,-32.75 70,-32.75 70,0 124,0 124,-32.75\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"97\" y=\"-7.25\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n",
       "</g>\n",
       "<!-- 5716332832 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>5716332832</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"141,-89.5 53,-89.5 53,-68.75 141,-68.75 141,-89.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"97\" y=\"-76\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 5716332832&#45;&gt;5720181328 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>5716332832&#45;&gt;5720181328</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M97,-68.36C97,-61.89 97,-53.05 97,-44.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100.5,-44.55 97,-34.55 93.5,-44.55 100.5,-44.55\"/>\n",
       "</g>\n",
       "<!-- 5716336720 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>5716336720</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"141,-146.25 53,-146.25 53,-125.5 141,-125.5 141,-146.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"97\" y=\"-132.75\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 5716336720&#45;&gt;5716332832 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>5716336720&#45;&gt;5716332832</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M97,-125.09C97,-118.47 97,-109.47 97,-101.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100.5,-101.34 97,-91.34 93.5,-101.34 100.5,-101.34\"/>\n",
       "</g>\n",
       "<!-- 5716332304 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>5716332304</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"88,-203 0,-203 0,-182.25 88,-182.25 88,-203\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"44\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n",
       "</g>\n",
       "<!-- 5716332304&#45;&gt;5716336720 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>5716332304&#45;&gt;5716336720</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M53.48,-181.84C60.79,-174.28 71.09,-163.64 79.84,-154.6\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"82.11,-157.29 86.55,-147.67 77.08,-152.42 82.11,-157.29\"/>\n",
       "</g>\n",
       "<!-- 5716333360 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>5716333360</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"147,-259.75 47,-259.75 47,-239 147,-239 147,-259.75\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"97\" y=\"-246.25\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 5716333360&#45;&gt;5716332304 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>5716333360&#45;&gt;5716332304</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M87.52,-238.59C80.21,-231.03 69.91,-220.39 61.16,-211.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"63.92,-209.17 54.45,-204.42 58.89,-214.04 63.92,-209.17\"/>\n",
       "</g>\n",
       "<!-- 5716328896 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>5716328896</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"194,-203 106,-203 106,-182.25 194,-182.25 194,-203\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"150\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n",
       "</g>\n",
       "<!-- 5716333360&#45;&gt;5716328896 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5716333360&#45;&gt;5716328896</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M106.48,-238.59C113.79,-231.03 124.09,-220.39 132.84,-211.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"135.11,-214.04 139.55,-204.42 130.08,-209.17 135.11,-214.04\"/>\n",
       "</g>\n",
       "<!-- 5720096384 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5720096384</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"124,-329.25 70,-329.25 70,-295.75 124,-295.75 124,-329.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"97\" y=\"-315.75\" font-family=\"monospace\" font-size=\"10.00\">x</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"97\" y=\"-303\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n",
       "</g>\n",
       "<!-- 5720096384&#45;&gt;5716333360 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>5720096384&#45;&gt;5716333360</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M97,-295.44C97,-288.1 97,-279.32 97,-271.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100.5,-271.73 97,-261.73 93.5,-271.73 100.5,-271.73\"/>\n",
       "</g>\n",
       "<!-- 5716328896&#45;&gt;5716336720 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>5716328896&#45;&gt;5716336720</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M140.52,-181.84C133.21,-174.28 122.91,-163.64 114.16,-154.6\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"116.92,-152.42 107.45,-147.67 111.89,-157.29 116.92,-152.42\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x154b85eb0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = x**2 + 3*x + 5\n",
    "\n",
    "# visualize the graph\n",
    "make_dot(y, params={\"x\": x})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fabe8a",
   "metadata": {},
   "source": [
    "### More realistic example of autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9b08c916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial parameters are: w=1.0, b=1.0\n",
      "Our model's prediction: 4.0\n",
      "The loss (how wrong we are): 9.0\n",
      "Autograd results:\n",
      "Gradient of loss with respect to w (dl/dw): -18.0\n",
      "Gradient of loss with respect to b (dl/db): -6.0\n"
     ]
    }
   ],
   "source": [
    "# 1. The data: single input and single output\n",
    "x_input = torch.tensor([3.0])\n",
    "y_ground_truth = torch.tensor([7.0])\n",
    "\n",
    "# 2. Model parameters: weight and bias. Our knobs that model will learn\n",
    "# we start with random initilized values. Well there are better ways to initialize these values such as Xavier initialization or He initialization but for simplicity we will use fixed random values here.\n",
    "w = torch.tensor([1.0], requires_grad=True)  # weight. Can also randomly initialize\n",
    "b = torch.tensor([1.0], requires_grad=True)  # bias\n",
    "print(f\"Initial parameters are: w={w.item()}, b={b.item()}\")\n",
    "\n",
    "# 3. Our single training step\n",
    "# guess the output, calculate loss, compute gradients, update parameters\n",
    "y_predicted = w * x_input + b  # linear model\n",
    "print(f\"Our model's prediction: {y_predicted.item()}\")\n",
    "loss = (y_predicted - y_ground_truth)**2  # mean squared error loss\n",
    "print(f\"The loss (how wrong we are): {loss.item()}\")\n",
    "\n",
    "# compute gradients\n",
    "loss.backward()\n",
    "\n",
    "print(\"Autograd results:\")\n",
    "print(f\"Gradient of loss with respect to w (dl/dw): {w.grad.item()}\")\n",
    "print(f\"Gradient of loss with respect to b (dl/db): {b.grad.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65758f1a",
   "metadata": {},
   "source": [
    "So what do these gradient numbers mean?\n",
    "    \n",
    "1. `w.grad` is -18.00. This is a large negative number. It tells us two things:\n",
    "   - The loss is very sensitive to changes in `w`.\n",
    "   - Since the gradient is negative, increasing `w` will decrease the loss. This is our 'compass' telling us the downhill direction for `w` is 'up'! This makes perfect sense, our `w` of 1 was too small to get to the target of 7.\n",
    "2. `b.grad` is -6.00. This is also negative.\n",
    "   - It tells us that to go 'downhill' on the loss, we should also increase `b`. Again, this makes sense.\n",
    "\n",
    "The next step, which an optimizer would do for us, is to take these gradients and update the weights: `w = w - learning_rate * w.grad` and `b = b - learning_rate * b.grad`. This single example shows the entire information flow required for a model to learn from a single mistake.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ae67b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 14.0.1 (20251006.0113)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"220pt\" height=\"407pt\"\n",
       " viewBox=\"0.00 0.00 220.00 407.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 402.75)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-402.75 216,-402.75 216,4 -4,4\"/>\n",
       "<!-- 5647627792 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>5647627792</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"133,-32.75 79,-32.75 79,0 133,0 133,-32.75\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"106\" y=\"-7.25\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 5716337872 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>5716337872</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"150,-89.5 62,-89.5 62,-68.75 150,-68.75 150,-89.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"106\" y=\"-76\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n",
       "</g>\n",
       "<!-- 5716337872&#45;&gt;5647627792 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>5716337872&#45;&gt;5647627792</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M106,-68.36C106,-61.89 106,-53.05 106,-44.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"109.5,-44.55 106,-34.55 102.5,-44.55 109.5,-44.55\"/>\n",
       "</g>\n",
       "<!-- 5716338016 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>5716338016</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"150,-146.25 62,-146.25 62,-125.5 150,-125.5 150,-146.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"106\" y=\"-132.75\" font-family=\"monospace\" font-size=\"10.00\">SubBackward0</text>\n",
       "</g>\n",
       "<!-- 5716338016&#45;&gt;5716337872 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>5716338016&#45;&gt;5716337872</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M106,-125.09C106,-118.47 106,-109.47 106,-101.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"109.5,-101.34 106,-91.34 102.5,-101.34 109.5,-101.34\"/>\n",
       "</g>\n",
       "<!-- 5716337728 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>5716337728</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"150,-203 62,-203 62,-182.25 150,-182.25 150,-203\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"106\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 5716337728&#45;&gt;5716338016 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>5716337728&#45;&gt;5716338016</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M106,-181.84C106,-175.22 106,-166.22 106,-158.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"109.5,-158.09 106,-148.09 102.5,-158.09 109.5,-158.09\"/>\n",
       "</g>\n",
       "<!-- 5716334800 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>5716334800</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"94,-259.75 6,-259.75 6,-239 94,-239 94,-259.75\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"50\" y=\"-246.25\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n",
       "</g>\n",
       "<!-- 5716334800&#45;&gt;5716337728 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>5716334800&#45;&gt;5716337728</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M60.01,-238.59C67.74,-231.03 78.63,-220.39 87.87,-211.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"90.29,-213.88 94.99,-204.39 85.4,-208.87 90.29,-213.88\"/>\n",
       "</g>\n",
       "<!-- 5716338256 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5716338256</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"100,-322.88 0,-322.88 0,-302.12 100,-302.12 100,-322.88\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"50\" y=\"-309.38\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 5716338256&#45;&gt;5716334800 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>5716338256&#45;&gt;5716334800</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50,-301.68C50,-293.52 50,-281.63 50,-271.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-271.48 50,-261.48 46.5,-271.48 53.5,-271.48\"/>\n",
       "</g>\n",
       "<!-- 5647469056 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>5647469056</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"77,-398.75 23,-398.75 23,-365.25 77,-365.25 77,-398.75\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"50\" y=\"-385.25\" font-family=\"monospace\" font-size=\"10.00\">w</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"50\" y=\"-372.5\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 5647469056&#45;&gt;5716338256 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>5647469056&#45;&gt;5716338256</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50,-365C50,-355.9 50,-344.39 50,-334.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-334.84 50,-324.84 46.5,-334.84 53.5,-334.84\"/>\n",
       "</g>\n",
       "<!-- 5716336432 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>5716336432</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"212,-259.75 112,-259.75 112,-239 212,-239 212,-259.75\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"162\" y=\"-246.25\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 5716336432&#45;&gt;5716337728 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5716336432&#45;&gt;5716337728</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M151.99,-238.59C144.26,-231.03 133.37,-220.39 124.13,-211.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"126.6,-208.87 117.01,-204.39 121.71,-213.88 126.6,-208.87\"/>\n",
       "</g>\n",
       "<!-- 5647629072 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>5647629072</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"189,-329.25 135,-329.25 135,-295.75 189,-295.75 189,-329.25\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"162\" y=\"-315.75\" font-family=\"monospace\" font-size=\"10.00\">b</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"162\" y=\"-303\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 5647629072&#45;&gt;5716336432 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>5647629072&#45;&gt;5716336432</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M162,-295.44C162,-288.1 162,-279.32 162,-271.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"165.5,-271.73 162,-261.73 158.5,-271.73 165.5,-271.73\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x154b87410>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plotting computation graph using torchviz\n",
    "make_dot(loss, params={\"w\": w, \"b\": b})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a45b79ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After one parameter update, our model's prediction: 4.6000\n",
      "After one parameter update, the loss (how wrong we are): 5.7600\n"
     ]
    }
   ],
   "source": [
    "# update the parameters using gradient descent and run a single training step again\n",
    "learning_rate = 0.01\n",
    "with torch.no_grad():  # we don't want to track these operations for autograd\n",
    "    w -= learning_rate * w.grad\n",
    "    b -= learning_rate * b.grad\n",
    "    # zero the gradients after updating. \n",
    "    # !! THIS IS VERY IMPORTANT TO AVOID ACCUMULATING GRADIENTS. \n",
    "    # If we don't zero the gradients, they will keep adding up in subsequent backward() calls\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "    \n",
    "# run another training step\n",
    "y_predicted = w * x_input + b  # linear model\n",
    "print(f\"After one parameter update, our model's prediction: {y_predicted.item():.4f}\")\n",
    "loss = (y_predicted - y_ground_truth)**2  # mean squared error loss\n",
    "print(f\"After one parameter update, the loss (how wrong we are): {loss.item():.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
